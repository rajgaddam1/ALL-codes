{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77uagh1jrSSB",
   "metadata": {
    "id": "77uagh1jrSSB"
   },
   "source": [
    "**Anomaly Detection** \n",
    "\n",
    "Abnormalities like fraud detection differ from the regular data in terms of patterns. An important characteristic of any anomaly dataset is class imbalance. To train a supervised model on such imbalanced dataset will not lead to promising results. The concept is that we train an unsupervised autoencoder on normal data, so all the feature generations that it will learn will be based on the characteristics of normal data and hence the reconstruction error will be low for non-fraud data.\n",
    "\n",
    "After the training is done, take a fraud record and pass itinto the autoencoder network and calculate the reconstruction error. This will be high because none of the features that the model learnt can explain this fraud. \n",
    "\n",
    "So, we can identify whether a particular datapoint is fraud or not based on the error. All samples for which the reconstruction error is small are similar to normal data. Those samples for which the reconstruction error is high are the anomalies.\n",
    "\n",
    "Similar thing can be applied to train cat and dog problem. Let’s say we train an autoencoder on cats, the only features it learns is about cats. After the training is done let us say we pass a dog to the autoencoder network, the construction looks like a cat because the network doesn’t know anything about the dog and the reconstruction error will be high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0172f9",
   "metadata": {
    "id": "9b0172f9"
   },
   "source": [
    "#### Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aklS3jwM7GaG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aklS3jwM7GaG",
    "outputId": "9ffff2ed-707d-416f-8bd4-4d1c10191579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154d4d84",
   "metadata": {
    "id": "154d4d84"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ca916",
   "metadata": {
    "id": "625ca916"
   },
   "source": [
    "#### Reading and Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ALmUksa87Und",
   "metadata": {
    "id": "ALmUksa87Und"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"/content/drive/MyDrive/autoencoders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87423b54",
   "metadata": {
    "id": "87423b54"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Fraud_data_amtstd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65822a95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65822a95",
    "outputId": "37e5c0a8-0cd7-4819-f459-ee7af33d3fd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64456, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensions\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8b9a10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "7a8b9a10",
    "outputId": "6b60ad9a-61ef-4ba8-d0a0-4ee51843e11b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.836500</td>\n",
       "      <td>-0.545419</td>\n",
       "      <td>-0.462979</td>\n",
       "      <td>0.537174</td>\n",
       "      <td>-0.426143</td>\n",
       "      <td>-0.100606</td>\n",
       "      <td>-0.584764</td>\n",
       "      <td>-0.103956</td>\n",
       "      <td>2.268429</td>\n",
       "      <td>-0.365185</td>\n",
       "      <td>0.122337</td>\n",
       "      <td>-2.117327</td>\n",
       "      <td>2.261481</td>\n",
       "      <td>1.287914</td>\n",
       "      <td>0.197872</td>\n",
       "      <td>0.495713</td>\n",
       "      <td>0.043528</td>\n",
       "      <td>0.317547</td>\n",
       "      <td>-0.662213</td>\n",
       "      <td>0.013151</td>\n",
       "      <td>0.085111</td>\n",
       "      <td>0.410736</td>\n",
       "      <td>0.137625</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.350260</td>\n",
       "      <td>0.464407</td>\n",
       "      <td>-0.070917</td>\n",
       "      <td>-0.030486</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.289880</td>\n",
       "      <td>-2.576061</td>\n",
       "      <td>-0.092256</td>\n",
       "      <td>1.976405</td>\n",
       "      <td>2.810033</td>\n",
       "      <td>-2.669128</td>\n",
       "      <td>-0.981883</td>\n",
       "      <td>-0.470310</td>\n",
       "      <td>-0.025692</td>\n",
       "      <td>0.099528</td>\n",
       "      <td>0.803329</td>\n",
       "      <td>-0.042235</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>-1.413220</td>\n",
       "      <td>2.000006</td>\n",
       "      <td>-0.096278</td>\n",
       "      <td>1.752810</td>\n",
       "      <td>-0.252515</td>\n",
       "      <td>0.462189</td>\n",
       "      <td>-1.320905</td>\n",
       "      <td>-0.473240</td>\n",
       "      <td>-0.307295</td>\n",
       "      <td>-2.789549</td>\n",
       "      <td>0.578976</td>\n",
       "      <td>-0.837979</td>\n",
       "      <td>0.372843</td>\n",
       "      <td>0.353451</td>\n",
       "      <td>-1.662202</td>\n",
       "      <td>-0.347171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.131318</td>\n",
       "      <td>0.139818</td>\n",
       "      <td>0.586921</td>\n",
       "      <td>1.069291</td>\n",
       "      <td>-0.334908</td>\n",
       "      <td>-0.204938</td>\n",
       "      <td>-0.135526</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>-0.121117</td>\n",
       "      <td>0.182139</td>\n",
       "      <td>1.034059</td>\n",
       "      <td>0.846406</td>\n",
       "      <td>0.149111</td>\n",
       "      <td>0.385353</td>\n",
       "      <td>0.414530</td>\n",
       "      <td>0.657300</td>\n",
       "      <td>-0.925449</td>\n",
       "      <td>0.501254</td>\n",
       "      <td>-0.067021</td>\n",
       "      <td>-0.043168</td>\n",
       "      <td>-0.028126</td>\n",
       "      <td>-0.167062</td>\n",
       "      <td>-0.048054</td>\n",
       "      <td>-0.009912</td>\n",
       "      <td>0.417694</td>\n",
       "      <td>-0.479793</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>-0.208963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.866956</td>\n",
       "      <td>1.373947</td>\n",
       "      <td>1.948343</td>\n",
       "      <td>2.686750</td>\n",
       "      <td>-0.366790</td>\n",
       "      <td>0.568632</td>\n",
       "      <td>-0.278349</td>\n",
       "      <td>0.739536</td>\n",
       "      <td>-1.655955</td>\n",
       "      <td>0.708396</td>\n",
       "      <td>0.871947</td>\n",
       "      <td>0.586652</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.391226</td>\n",
       "      <td>0.844220</td>\n",
       "      <td>0.703376</td>\n",
       "      <td>-0.365869</td>\n",
       "      <td>0.837992</td>\n",
       "      <td>1.036112</td>\n",
       "      <td>0.328626</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>-0.070619</td>\n",
       "      <td>-0.080307</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>0.159131</td>\n",
       "      <td>0.157940</td>\n",
       "      <td>-0.014370</td>\n",
       "      <td>-0.253595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.842670</td>\n",
       "      <td>1.401843</td>\n",
       "      <td>0.927235</td>\n",
       "      <td>1.070402</td>\n",
       "      <td>0.843883</td>\n",
       "      <td>0.467333</td>\n",
       "      <td>0.366716</td>\n",
       "      <td>0.616739</td>\n",
       "      <td>-1.586963</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.409240</td>\n",
       "      <td>0.139799</td>\n",
       "      <td>0.319222</td>\n",
       "      <td>0.538952</td>\n",
       "      <td>-0.760940</td>\n",
       "      <td>1.572230</td>\n",
       "      <td>-1.475274</td>\n",
       "      <td>0.748143</td>\n",
       "      <td>-0.725295</td>\n",
       "      <td>-0.208826</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>-0.182581</td>\n",
       "      <td>-0.226834</td>\n",
       "      <td>-1.029794</td>\n",
       "      <td>-0.118762</td>\n",
       "      <td>-0.228960</td>\n",
       "      <td>-0.024250</td>\n",
       "      <td>0.046547</td>\n",
       "      <td>-0.346230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4  ...       V27       V28    Amount  Class\n",
       "0  1.836500 -0.545419 -0.462979  0.537174  ... -0.070917 -0.030486  0.049882    0.0\n",
       "1 -4.289880 -2.576061 -0.092256  1.976405  ...  0.353451 -1.662202 -0.347171    0.0\n",
       "2  1.131318  0.139818  0.586921  1.069291  ...  0.024360  0.023878 -0.208963    0.0\n",
       "3 -0.866956  1.373947  1.948343  2.686750  ...  0.157940 -0.014370 -0.253595    0.0\n",
       "4 -0.842670  1.401843  0.927235  1.070402  ... -0.024250  0.046547 -0.346230    0.0\n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first few records of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49182380",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49182380",
    "outputId": "6493a788-a4e1-4a48-86dc-76376850c73d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6074906f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6074906f",
    "outputId": "bb081932-038c-41cc-ef4e-a1310409edd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8f212",
   "metadata": {
    "id": "92c8f212"
   },
   "source": [
    "#### Data distribution w.r.t the target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed4c4fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bed4c4fa",
    "outputId": "aa57884c-401c-4c85-abe6-168735ab9e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Target Distribution***\n",
      "\n",
      "0.0    64147\n",
      "1.0      308\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "***Target Distribution in Percentage***\n",
      "\n",
      "0.9952060320218443\n",
      "0.0047784535186794095\n"
     ]
    }
   ],
   "source": [
    "print(\"**Target Distribution***\\n\")\n",
    "print(pd.value_counts(data['Class']))\n",
    "print(\"\\n\\n\")\n",
    "print(\"***Target Distribution in Percentage***\\n\")\n",
    "print(pd.value_counts(data['Class'])[0]/data['Class'].shape[0])\n",
    "print(pd.value_counts(data['Class'])[1]/data['Class'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690fafc",
   "metadata": {
    "id": "7690fafc"
   },
   "source": [
    "#### Let's visualize the target distribution using a barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39ba1b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "f39ba1b3",
    "outputId": "0054772f-8427-491b-b2aa-c218c1e8bf40"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdXklEQVR4nO3deZgdZYHv8e+PhFWBsMSISSAwRBxEwRAB94UrBHAGXAZRNJGHIeMVXAZ1AMc7cRnmos8oiwuKEkhQZBXJyBIiiop3AgmIQFiGgGAStkgCkZ3A7/5Rb0PROZ0+qfTpptO/z/Oc51S99VbVW6dPn9+pt+pUyTYRERFNrDfQDYiIiMErIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkhixJj0raoR/X93FJV/fX+lqs/0xJ/16G3ybp9j5c9mWSppThPt1OSYdKuqKvlhd9KyESbSsful2P5yQ9URs/dKDbtzqSrpL0j/Uy2y+3fddAtWkg2f6d7Z16qyfpy5J+3Mby9rM9Y23bJWmcJEsaXlv2T2zvs7bLjs4Y3nuViIrtl3cNS7ob+Efbv+xeT9Jw2yv7s20xMCQJkO3nBrotMTCyJxJrTdI7JS2WdIyk+4EzJG0h6ReSlkpaXobH1Oa5StLXJP1e0l8lXSFp6zJtI0k/lvSQpIclzZM0qkw7TNKtZZ67JP1Tt7YcKOkGSSsk3SlpkqTjgbcB3yl7Td8pdS1pxzK8uaSZpb33SPqSpPXKtI9LulrSf5Zt+ZOk/VbzeoyV9LOyrIe61tei3smSFpW2XifpbbVpe0iaX6Y9IOlbvb02LZb/BknXl9fqXGCj7n+z2vgxkpaUurdL2lvSJOCLwIfK6/bH2t/ueEm/Bx4HdmixpydJ35H0iKTbJO1dm3C3pP9VG6/v7fy2PD9c1vmm7t1jkt5ctvuR8vzm2rQe31fRGQmR6CuvBLYEtgOmUr23zijj2wJPAN0/TD8CHAa8AtgA+HwpnwJsDowFtgI+UeYHeBB4L7BZmfdESROg+uAFZgJfAEYAbwfutv2vwO+Ao0oX1lEt2v/tss4dgHcAk8vyu+wJ3A5sDXwDOL18C38RScOAXwD3AOOA0cA5LV8xmAfsRvW6nQ2cL6nrg/5k4GTbmwF/A5zXxmtTb8cGwM+Bs8ryzwc+0KoRknYCjgLeaHtTYF+q1+1y4D+Ac8vrtmttto9R/Z03Ldva3Z7AnVSv1zTgZ5K27OF1qHt7eR5R1vnf3dq6JXAJcArV9n8LuETSVrVqPb2vogMSItFXngOm2X7K9hO2H7J9oe3Hbf8VOJ7qw7nuDNv/Y/sJqg/J3Ur5M1QfEDvaftb2dbZXANi+xPadrvwGuIJqLwPgcGC67Tm2n7O9xPZtvTW8fPAfAhxn+6+27wa+SfVB2eUe2z+0/SwwA9gGaLUHsAfwKuALth+z/aTtlgeZbf+4vE4rbX8T2BDoOk7xDLCjpK1tP2p7bm+vTTd7AesDJ9l+xvYFVKHVyrNl3TtLWt/23bbv7KFulzNtLyhtf6bF9Adr6z6XKoAP6GWZ7TgAuMP2WWXdPwVuA/6uVqen91V0QEIk+spS2092jUjaRNIPStfQCqpuihHlA7vL/bXhx4GuYy5nAbOBcyTdK+kbktYvy91P0lxJyyQ9DOxP9W0Xqm/nvX34tbI11Qdu/Rv1PVR7Eau01fbjZfDlrGosVeD0ekxI0udL19wjZVs254VtORx4NXBb6bJ5bynv8bXp5lXAEr/4Cqut9hiwvRD4LPBl4EFJ50h6VS/NX9TL9Fbr7m2Z7XgVq25Hj38rXvy+ig5IiERf6X456M9Rfaves3TJdHVTrNIFtMqCqm+vX7G9M/Bmqu6ryZI2BC4E/hMYZXsEcGltmYuoun7aaV/dX6i+4W9XK9sWWNJbW1tYBGyr2tlFrZTjH/8CHAxsUbblEcq22L7D9oepumS+Dlwg6WU9vTYtVnEfMLpbl9u2PbXH9tm230r1GrisE3p+3Xq7/Herdd9bhh8DNqlNe+UaLPdeXvx36lp2k79V9IGESHTKplR99Q+Xfuxp7c4o6V2SXlf2WlZQfcA/R9W/vSGwFFhZDm7XT/08HTisHBReT9JoSa8p0x6gOt6xitJFdR5wvKRNJW0HHA30emprC9dSfYCfIOll5UD4W1rU2xRYWbZluKR/ozrO0/UafFTSyHLW08Ol+LnVvDbd/XdZ/qclrS/p/VRdbauQtJOkd5eQfpLq79a1zAeAcSonGayBV9TW/Q/A31IFPsANwCFl2kTgg7X5lpZ19/T7nUuBV0v6iKThkj4E7Ex1HCoGQEIkOuUkYGOqb/lzgcvXYN5XAhdQfUjeCvwGOKscW/k01Qf+cqoDqLO6ZrJ9LeVgO9W3+t/wwrfWk4EPqjq76pQW6/wU1Tfku4CrqQ50T1+DNne14Vmq/vkdgT8Di4EPtag6m+o1+R+q7pgneXEX0SRggaRHS9sPKX38LV+bFu14Gng/8HFgWWnDz3po9obACVR/q/upAuC4Mu388vyQpOtXu/Evdg0wvizzeOCDth8q0/4P1R7jcuArVK91V7sfL/V/r+rss726bddDVHtfnwMeotqbe6/tv6xB26IPKTelioiIprInEhERjSVEIiKisYRIREQ0lhCJiIjGhtwFGLfeemuPGzduoJsRETFoXHfddX+xPbLVtCEXIuPGjWP+/PkD3YyIiEFDUsurHUC6syIiYi0kRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0NuV+sDwbjjr1koJuwTrn7hAMGugkR66zsiURERGMJkYiIaCwhEhERjSVEIiKisYRIREQ0lhCJiIjGEiIREdFYQiQiIhpLiERERGMdDRFJIyRdIOk2SbdKepOkLSXNkXRHed6i1JWkUyQtlHSjpAm15Uwp9e+QNKVWvrukm8o8p0hSJ7cnIiJerNN7IicDl9t+DbArcCtwLHCl7fHAlWUcYD9gfHlMBU4FkLQlMA3YE9gDmNYVPKXOEbX5JnV4eyIioqZjISJpc+DtwOkAtp+2/TBwIDCjVJsBHFSGDwRmujIXGCFpG2BfYI7tZbaXA3OASWXaZrbn2jYws7asiIjoB53cE9keWAqcIekPkn4k6WXAKNv3lTr3A6PK8GhgUW3+xaVsdeWLW5SvQtJUSfMlzV+6dOlablZERHTpZIgMByYAp9p+A/AYL3RdAVD2INzBNnSt5zTbE21PHDlyZKdXFxExZHQyRBYDi21fU8YvoAqVB0pXFOX5wTJ9CTC2Nv+YUra68jEtyiMiop90LERs3w8skrRTKdobuAWYBXSdYTUFuLgMzwIml7O09gIeKd1es4F9JG1RDqjvA8wu01ZI2quclTW5tqyIiOgHnb4p1aeAn0jaALgLOIwquM6TdDhwD3BwqXspsD+wEHi81MX2MklfA+aVel+1vawMfxI4E9gYuKw8IiKin3Q0RGzfAExsMWnvFnUNHNnDcqYD01uUzwd2WctmRkREQ/nFekRENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY11NEQk3S3pJkk3SJpfyraUNEfSHeV5i1IuSadIWijpRkkTasuZUurfIWlKrXz3svyFZV51cnsiIuLF+mNP5F22d7M9sYwfC1xpezxwZRkH2A8YXx5TgVOhCh1gGrAnsAcwrSt4Sp0javNN6vzmREREl4HozjoQmFGGZwAH1cpnujIXGCFpG2BfYI7tZbaXA3OASWXaZrbn2jYws7asiIjoB50OEQNXSLpO0tRSNsr2fWX4fmBUGR4NLKrNu7iUra58cYvyVUiaKmm+pPlLly5dm+2JiIia4R1e/lttL5H0CmCOpNvqE21bkjvcBmyfBpwGMHHixI6vLyJiqOjonojtJeX5QeAiqmMaD5SuKMrzg6X6EmBsbfYxpWx15WNalEdERD/pWIhIepmkTbuGgX2Am4FZQNcZVlOAi8vwLGByOUtrL+CR0u01G9hH0hblgPo+wOwybYWkvcpZWZNry4qIiH7Qye6sUcBF5azb4cDZti+XNA84T9LhwD3AwaX+pcD+wELgceAwANvLJH0NmFfqfdX2sjL8SeBMYGPgsvKIiIh+0rEQsX0XsGuL8oeAvVuUGziyh2VNB6a3KJ8P7LLWjY2IiEbyi/WIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjbYWIpNc1XYGkYZL+IOkXZXx7SddIWijpXEkblPINy/jCMn1cbRnHlfLbJe1bK59UyhZKOrZpGyMiopl290S+J+laSZ+UtPkaruMzwK218a8DJ9reEVgOHF7KDweWl/ITSz0k7QwcArwWmFTaMkzSMOC7wH7AzsCHS92IiOgnbYWI7bcBhwJjgesknS3pPb3NJ2kMcADwozIu4N3ABaXKDOCgMnxgGadM37vUPxA4x/ZTtv8ELAT2KI+Ftu+y/TRwTqkbERH9pO1jIrbvAL4EHAO8AzhF0m2S3r+a2U4C/gV4roxvBTxse2UZXwyMLsOjgUVlXSuBR0r958u7zdNT+SokTZU0X9L8pUuXtrG1ERHRjnaPibxe0olU3VLvBv7O9t+W4RN7mOe9wIO2r+urxjZl+zTbE21PHDly5EA3JyJinTG8zXrfpuqS+qLtJ7oKbd8r6Us9zPMW4O8l7Q9sBGwGnAyMkDS87G2MAZaU+kuoussWSxoObA48VCvvUp+np/KIiOgH7XZnHQCc3RUgktaTtAmA7bNazWD7ONtjbI+jOjD+K9uHAr8GPliqTQEuLsOzyjhl+q9su5QfUs7e2h4YD1wLzAPGl7O9NijrmNXm9kRERB9oN0R+CWxcG9+klDVxDHC0pIVUxzxOL+WnA1uV8qOBYwFsLwDOA24BLgeOtP1s2ZM5CphN1c12XqkbERH9pN3urI1sP9o1YvvRrj2Rdti+CriqDN9FdWZV9zpPAv/Qw/zHA8e3KL8UuLTddkRERN9qd0/kMUkTukYk7Q48sZr6ERExBLS7J/JZ4HxJ9wICXgl8qGOtioiIQaGtELE9T9JrgJ1K0e22n+lcsyIiYjBod08E4I3AuDLPBEnYntmRVkVExKDQVohIOgv4G+AG4NlSbCAhEhExhLW7JzIR2Ln8biMiIgJo/+ysm6kOpkdERDyv3T2RrYFbJF0LPNVVaPvvO9KqiIgYFNoNkS93shERETE4tXuK728kbQeMt/3L8mv1YZ1tWkREvNS1eyn4I6huFPWDUjQa+HmnGhUREYNDuwfWj6S6tPsKeP4GVa/oVKMiImJwaDdEniq3oAWg3O8jp/tGRAxx7YbIbyR9Edi43Fv9fOC/OtesiIgYDNoNkWOBpcBNwD9RXX69pzsaRkTEENHu2VnPAT8sj4iICKD9a2f9iRbHQGzv0OctioiIQWNNrp3VZSOqOxBu2ffNiYiIwaStYyK2H6o9ltg+CTigw22LiIiXuHa7sybURtej2jNZk3uRRETEOqjdIPhmbXglcDdwcJ+3JiIiBpV2z856V6cbEhERg0+73VlHr2667W/1TXMiImIwaffHhhOB/0114cXRwCeACcCm5bEKSRtJulbSHyUtkPSVUr69pGskLZR0rqQNSvmGZXxhmT6utqzjSvntkvatlU8qZQslHbvmmx8REWuj3WMiY4AJtv8KIOnLwCW2P7qaeZ4C3m37UUnrA1dLugw4GjjR9jmSvg8cDpxanpfb3lHSIcDXgQ9J2hk4BHgt8Crgl5JeXdbxXeA9wGJgnqRZtm9pe+sjImKttLsnMgp4ujb+dCnrkSuPltH1y8PAu6kuKw8wAzioDB9YxinT95akUn6O7ads/wlYCOxRHgtt31UuDnlOqRsREf2k3T2RmcC1ki4q4wfxwgd+jyQNA64DdqTaa7gTeNj2ylJlMVX3GOV5EYDtlZIeAbYq5XNri63Ps6hb+Z49tGMqMBVg22237a3ZERHRpnZ/bHg8cBiwvDwOs/0fbcz3rO3dqLrD9gBesxZtbcz2abYn2p44cuTIgWhCRMQ6qd3uLIBNgBW2TwYWS9q+3RltPwz8GngTMKLcjwSqcFlShpcAY+H5+5VsDjxUL+82T0/lERHRT9q9Pe404BjguFK0PvDjXuYZKWlEGd6Y6gD4rVRh8sFSbQpwcRmeVcYp039l26X8kHL21vbAeOBaYB4wvpzttQHVwfdZ7WxPRET0jXaPibwPeANwPYDteyW1PLW3ZhtgRjkush5wnu1fSLoFOEfSvwN/AE4v9U8HzpK0EFhGFQrYXiDpPOAWql/LH2n7WQBJRwGzgWHAdNsL2tyeiIjoA+2GyNO2LckAkl7W2wy2b6QKnu7ld1EdH+le/iTV1YFbLet44PgW5ZdS3SArIiIGQLvHRM6T9AOq4xlHAL8kN6iKiBjyet0TKb/VOJfqzKoVwE7Av9me0+G2RUTES1yvIVK6sS61/TogwREREc9rtzvreklv7GhLIiJi0Gn3wPqewEcl3Q08BohqJ+X1nWpYRES89K02RCRta/vPwL6rqxcREUNTb3siP6e6eu89ki60/YH+aFRERAwOvR0TUW14h042JCIiBp/eQsQ9DEdERPTanbWrpBVUeyQbl2F44cD6Zh1tXUREvKStNkRsD+uvhkRExOCzJpeCj4iIeJGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWMdCRNJYSb+WdIukBZI+U8q3lDRH0h3leYtSLkmnSFoo6UZJE2rLmlLq3yFpSq18d0k3lXlOkaRVWxIREZ3SyT2RlcDnbO8M7AUcKWln4FjgStvjgSvLOMB+wPjymAqcClXoANOo7vO+BzCtK3hKnSNq803q4PZEREQ3HQsR2/fZvr4M/xW4FRgNHAjMKNVmAAeV4QOBma7MBUZI2obq/u5zbC+zvRyYA0wq0zazPde2gZm1ZUVERD/ol2MiksYBbwCuAUbZvq9Muh8YVYZHA4tqsy0uZasrX9yivNX6p0qaL2n+0qVL12pbIiLiBR0PEUkvBy4EPmt7RX1a2YPo+G13bZ9me6LtiSNHjuz06iIihoyOhoik9akC5Ce2f1aKHyhdUZTnB0v5EmBsbfYxpWx15WNalEdERD/p5NlZAk4HbrX9rdqkWUDXGVZTgItr5ZPLWVp7AY+Ubq/ZwD6StigH1PcBZpdpKyTtVdY1ubasiIjoB6u9x/paegvwMeAmSTeUsi8CJwDnSTocuAc4uEy7FNgfWAg8DhwGYHuZpK8B80q9r9peVoY/CZwJbAxcVh4REdFPOhYitq8Gevrdxt4t6hs4sodlTQemtyifD+yyFs2MiIi1kF+sR0REYwmRiIhoLCESERGNJUQiIqKxhEhERDSWEImIiMYSIhER0VhCJCIiGkuIREREYwmRiIhoLCESERGNJUQiIqKxhEhERDSWEImIiMYSIhER0VhCJCIiGkuIREREYwmRiIhoLCESERGNJUQiIqKxhEhERDSWEImIiMYSIhER0VjHQkTSdEkPSrq5VralpDmS7ijPW5RySTpF0kJJN0qaUJtnSql/h6QptfLdJd1U5jlFkjq1LRER0Von90TOBCZ1KzsWuNL2eODKMg6wHzC+PKYCp0IVOsA0YE9gD2BaV/CUOkfU5uu+roiI6LCOhYjt3wLLuhUfCMwowzOAg2rlM12ZC4yQtA2wLzDH9jLby4E5wKQybTPbc20bmFlbVkRE9JP+PiYyyvZ9Zfh+YFQZHg0sqtVbXMpWV764RXlERPSjATuwXvYg3B/rkjRV0nxJ85cuXdofq4yIGBL6O0QeKF1RlOcHS/kSYGyt3phStrryMS3KW7J9mu2JtieOHDlyrTciIiIq/R0is4CuM6ymABfXyieXs7T2Ah4p3V6zgX0kbVEOqO8DzC7TVkjaq5yVNbm2rIiI6CfDO7VgST8F3glsLWkx1VlWJwDnSTocuAc4uFS/FNgfWAg8DhwGYHuZpK8B80q9r9ruOlj/SaozwDYGLiuPiIjoRx0LEdsf7mHS3i3qGjiyh+VMB6a3KJ8P7LI2bYyIiLWTX6xHRERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESERENJYQiYiIxhIiERHRWEIkIiIaG/QhImmSpNslLZR07EC3JyJiKBnUISJpGPBdYD9gZ+DDknYe2FZFRAwdwwe6AWtpD2Ch7bsAJJ0DHAjcMqCtiliHjTv2koFuwjrl7hMOGOgmrJXBHiKjgUW18cXAnt0rSZoKTC2jj0q6vR/aNhRsDfxloBvRG319oFsQAyTvz76zXU8TBnuItMX2acBpA92OdY2k+bYnDnQ7IlrJ+7N/DOpjIsASYGxtfEwpi4iIfjDYQ2QeMF7S9pI2AA4BZg1wmyIihoxB3Z1le6Wko4DZwDBguu0FA9ysoSRdhPFSlvdnP5DtgW5DREQMUoO9OysiIgZQQiQiIhpLiAxRkizpm7Xxz0v6cj+34SpJOQUzeiXpWUk31B7jOrCOuyVt3dfLXdcN6gPrsVaeAt4v6f/aXuMfZEkabntlB9oV0coTtndrNUGSqI7vPtfPbQqyJzKUraQ6e+Wfu0+QNE7SryTdKOlKSduW8jMlfV/SNcA3yvipkuZKukvSOyVNl3SrpDNryztV0nxJCyR9pb82MNZd5T16u6SZwM3A2J7eZ/U9DEkTJV1VhreSdEWp/yNAA7Etg11CZGj7LnCopM27lX8bmGH79cBPgFNq08YAb7Z9dBnfAngTVRjNAk4EXgu8TlLXN8d/Lb8cfj3wDkmv78jWxLps41pX1kWlbDzwPduvtX0Pa/4+mwZcbfu1wEXAth1r/TosITKE2V4BzAQ+3W3Sm4Czy/BZwFtr0863/Wxt/L9cnSd+E/CA7ZtKt8ICYFypc7Ck64E/UAVMrrQca+oJ27uVx/tK2T2259bqrOn77O3AjwFsXwIs7+tGDwU5JhInAdcDZ7RZ/7Fu40+V5+dqw13jwyVtD3weeKPt5aWba6PmzY143vPvxV7eZyt54Qtz3nt9LHsiQ5ztZcB5wOG14v9HdQkZgEOB363FKjaj+md/RNIoqnu/RPS11b3P7gZ2L8MfqJX/FvgIgKT9qLpmYw0lRALgm1SXze7yKeAwSTcCHwM+03TBtv9I1b1wG1UX2e/Xop0RLfXyPvsKcLKk+cCz3crfLmkB8H7gz/3U3HVKLnsSERGNZU8kIiIaS4hERERjCZGIiGgsIRIREY0lRCIiorGESESHSHqlpHMk3SnpOkmXSnq1pJsHum0RfSW/WI/ogHJl2YuorkF2SCnbFRg1oA2L6GPZE4nojHcBz9j+fldB+UHcoq7xciXa30m6vjzeXMq3kfTbcrHBmyW9TdKwctXkmyXdJGmVqy9HDITsiUR0xi7Adb3UeRB4j+0nJY0HfgpMpLoUx2zbx0saBmwC7AaMtr0LgKQRnWt6RPsSIhEDZ33gO+WS+c8Cry7l84DpktYHfm77Bkl3ATtI+jZwCXDFgLQ4opt0Z0V0xgJeuOhfT/4ZeADYlWoPZAMA27+lukz5EuBMSZNtLy/1rgI+AfyoM82OWDMJkYjO+BWwoaSpXQXlJklja3U2B+4r91/5GDCs1NuO6t4sP6QKiwnlznzr2b4Q+BIwoX82I2L10p0V0QG2Lel9wEmSjgGepLok+Wdr1b4HXChpMnA5L9wf453AFyQ9AzwKTAZGA2dI6vrid1zHNyKiDbmKb0RENJburIiIaCwhEhERjSVEIiKisYRIREQ0lhCJiIjGEiIREdFYQiQiIhr7/1DzNhEaGz5qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drawing a barplot\n",
    "pd.value_counts(data['Class']).plot(kind = 'bar', rot=0)\n",
    "# Giving titles and labels to the plot\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), [\"Normal\", \"Fraud\"])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ken-NLll7lP4",
   "metadata": {
    "id": "ken-NLll7lP4"
   },
   "source": [
    "O = Normal\n",
    "1 = Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978bb562",
   "metadata": {
    "id": "978bb562"
   },
   "source": [
    "#### Extracting numpy array from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02116c8",
   "metadata": {
    "id": "d02116c8"
   },
   "outputs": [],
   "source": [
    "data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d823819",
   "metadata": {
    "id": "5d823819"
   },
   "source": [
    "#### Train test split\n",
    "\n",
    "Splitting the data into train and test, such that train data has only non-fraud records and test data has both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c54c253",
   "metadata": {
    "id": "9c54c253"
   },
   "outputs": [],
   "source": [
    "data_nf = data[data[:,-1] == 0]\n",
    "test_f  = data[data[:,-1] == 1]\n",
    "\n",
    "train_nf, test_nf = train_test_split(data_nf, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "345a1674",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "345a1674",
    "outputId": "a7637f23-8068-41a2-ae93-452fc5513294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64456, 30)\n",
      "(51317, 30)\n",
      "(12830, 30)\n",
      "(308, 30)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(train_nf.shape)\n",
    "print(test_nf.shape)\n",
    "print(test_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee1ed2",
   "metadata": {
    "id": "40ee1ed2"
   },
   "source": [
    "#### Look at the distribution w.r.t target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b478d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b478d37",
    "outputId": "13044541-038a-4676-ad28-1c444105a0a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.,  1., nan]), array([64147,   308,     1]))\n",
      "(array([0.]), array([51317]))\n",
      "(array([0.]), array([12830]))\n",
      "(array([1.]), array([308]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(data[:,-1], return_counts=True))\n",
    "print(np.unique(train_nf[:,-1], return_counts=True))\n",
    "print(np.unique(test_nf[:,-1], return_counts=True))\n",
    "print(np.unique(test_f[:,-1], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a6536",
   "metadata": {
    "id": "fa7a6536"
   },
   "source": [
    "#### Extracting the independent features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "935341d1",
   "metadata": {
    "id": "935341d1"
   },
   "outputs": [],
   "source": [
    "X_train_nf = train_nf[:,:-1]\n",
    "X_test_nf = test_nf[:,:-1]\n",
    "X_test_f = test_f[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84481213",
   "metadata": {
    "id": "84481213"
   },
   "source": [
    "#### Building an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbf9746c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbf9746c",
    "outputId": "76ec4610-916c-455a-fcf2-d4a41ea0874e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train_nf.shape[1]\n",
    "encoding_dim = 150\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb70d216",
   "metadata": {
    "id": "bb70d216"
   },
   "outputs": [],
   "source": [
    "# Input placeholder\n",
    "input_att = Input(shape=(input_dim,))\n",
    "\n",
    "input_dropout = Dropout(0.2)(input_att)\n",
    " \n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_dropout)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(input_dim, activation='linear')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WU5QkRwH9jCQ",
   "metadata": {
    "id": "WU5QkRwH9jCQ"
   },
   "source": [
    "#### Check the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ad7e63",
   "metadata": {
    "id": "a2ad7e63"
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input_att, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "R7vnW6J_9nLM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7vnW6J_9nLM",
    "outputId": "11bcf628-3616-4126-eeef-f38b933aa60e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 29)]              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               4500      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                4379      \n",
      "=================================================================\n",
      "Total params: 8,879\n",
      "Trainable params: 8,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cba9ed",
   "metadata": {
    "id": "97cba9ed"
   },
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3164aa5c",
   "metadata": {
    "id": "3164aa5c"
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24137d4c",
   "metadata": {
    "id": "24137d4c"
   },
   "source": [
    "#### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "139b0f51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "139b0f51",
    "outputId": "424575f7-a5e4-45ee-b8c6-0409577c6a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1283/1283 [==============================] - 3s 2ms/step - loss: 0.2729 - val_loss: 0.0557\n",
      "Epoch 2/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1730 - val_loss: 0.0511\n",
      "Epoch 3/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1616 - val_loss: 0.0497\n",
      "Epoch 4/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1473 - val_loss: 0.0603\n",
      "Epoch 5/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1444 - val_loss: 0.0403\n",
      "Epoch 6/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1363 - val_loss: 0.0413\n",
      "Epoch 7/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1324 - val_loss: 0.0428\n",
      "Epoch 8/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1310 - val_loss: 0.0374\n",
      "Epoch 9/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1230 - val_loss: 0.0396\n",
      "Epoch 10/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1258 - val_loss: 0.0463\n",
      "Epoch 11/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1229 - val_loss: 0.0405\n",
      "Epoch 12/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1272 - val_loss: 0.0342\n",
      "Epoch 13/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1157 - val_loss: 0.0377\n",
      "Epoch 14/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1149 - val_loss: 0.0363\n",
      "Epoch 15/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1154 - val_loss: 0.0375\n",
      "Epoch 16/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1137 - val_loss: 0.0362\n",
      "Epoch 17/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1140 - val_loss: 0.0362\n",
      "Epoch 18/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1114 - val_loss: 0.0338\n",
      "Epoch 19/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1138 - val_loss: 0.0418\n",
      "Epoch 20/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1117 - val_loss: 0.0334\n",
      "Epoch 21/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1096 - val_loss: 0.0331\n",
      "Epoch 22/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1130 - val_loss: 0.0406\n",
      "Epoch 23/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1105 - val_loss: 0.0365\n",
      "Epoch 24/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1120 - val_loss: 0.0338\n",
      "Epoch 25/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1089 - val_loss: 0.0329\n",
      "Epoch 26/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1042 - val_loss: 0.0371\n",
      "Epoch 27/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1033 - val_loss: 0.0358\n",
      "Epoch 28/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1066 - val_loss: 0.0329\n",
      "Epoch 29/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1063 - val_loss: 0.0374\n",
      "Epoch 30/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1054 - val_loss: 0.0330\n",
      "Epoch 31/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1108 - val_loss: 0.0424\n",
      "Epoch 32/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1034 - val_loss: 0.0331\n",
      "Epoch 33/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1048 - val_loss: 0.0401\n",
      "Epoch 34/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1047 - val_loss: 0.0335\n",
      "Epoch 35/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0993 - val_loss: 0.0335\n",
      "Epoch 36/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1037 - val_loss: 0.0359\n",
      "Epoch 37/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1034 - val_loss: 0.0379\n",
      "Epoch 38/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1014 - val_loss: 0.0317\n",
      "Epoch 39/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1006 - val_loss: 0.0333\n",
      "Epoch 40/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1051 - val_loss: 0.0381\n",
      "Epoch 41/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1051 - val_loss: 0.0340\n",
      "Epoch 42/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1010 - val_loss: 0.0356\n",
      "Epoch 43/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1021 - val_loss: 0.0322\n",
      "Epoch 44/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0997 - val_loss: 0.0359\n",
      "Epoch 45/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0985 - val_loss: 0.0318\n",
      "Epoch 46/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0984 - val_loss: 0.0338\n",
      "Epoch 47/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1000 - val_loss: 0.0373\n",
      "Epoch 48/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0975 - val_loss: 0.0329\n",
      "Epoch 49/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0997 - val_loss: 0.0384\n",
      "Epoch 50/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1001 - val_loss: 0.0385\n",
      "Epoch 51/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0985 - val_loss: 0.0360\n",
      "Epoch 52/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0969 - val_loss: 0.0334\n",
      "Epoch 53/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0971 - val_loss: 0.0450\n",
      "Epoch 54/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1019 - val_loss: 0.0328\n",
      "Epoch 55/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0979 - val_loss: 0.0383\n",
      "Epoch 56/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0984 - val_loss: 0.0331\n",
      "Epoch 57/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0972 - val_loss: 0.0325\n",
      "Epoch 58/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0989 - val_loss: 0.0330\n",
      "Epoch 59/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0992 - val_loss: 0.0331\n",
      "Epoch 60/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1018 - val_loss: 0.0331\n",
      "Epoch 61/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0982 - val_loss: 0.0327\n",
      "Epoch 62/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0979 - val_loss: 0.0347\n",
      "Epoch 63/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0944 - val_loss: 0.0353\n",
      "Epoch 64/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0980 - val_loss: 0.0378\n",
      "Epoch 65/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0938 - val_loss: 0.0420\n",
      "Epoch 66/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0976 - val_loss: 0.0533\n",
      "Epoch 67/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0987 - val_loss: 0.0344\n",
      "Epoch 68/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0971 - val_loss: 0.0343\n",
      "Epoch 69/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0956 - val_loss: 0.0418\n",
      "Epoch 70/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0959 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0960 - val_loss: 0.0358\n",
      "Epoch 72/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0979 - val_loss: 0.0361\n",
      "Epoch 73/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0941 - val_loss: 0.0355\n",
      "Epoch 74/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0954 - val_loss: 0.0368\n",
      "Epoch 75/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0962 - val_loss: 0.0397\n",
      "Epoch 76/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0967 - val_loss: 0.0389\n",
      "Epoch 77/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0922 - val_loss: 0.0341\n",
      "Epoch 78/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0951 - val_loss: 0.0351\n",
      "Epoch 79/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0970 - val_loss: 0.0470\n",
      "Epoch 80/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0953 - val_loss: 0.0399\n",
      "Epoch 81/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0929 - val_loss: 0.0375\n",
      "Epoch 82/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0969 - val_loss: 0.0363\n",
      "Epoch 83/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0945 - val_loss: 0.0351\n",
      "Epoch 84/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0946 - val_loss: 0.0399\n",
      "Epoch 85/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0937 - val_loss: 0.0371\n",
      "Epoch 86/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0940 - val_loss: 0.0389\n",
      "Epoch 87/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0981 - val_loss: 0.0387\n",
      "Epoch 88/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0958 - val_loss: 0.0386\n",
      "Epoch 89/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0960 - val_loss: 0.0380\n",
      "Epoch 90/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.1003 - val_loss: 0.0350\n",
      "Epoch 91/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0926 - val_loss: 0.0390\n",
      "Epoch 92/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0975 - val_loss: 0.0386\n",
      "Epoch 93/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0941 - val_loss: 0.0378\n",
      "Epoch 94/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0965 - val_loss: 0.0383\n",
      "Epoch 95/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0936 - val_loss: 0.0360\n",
      "Epoch 96/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0927 - val_loss: 0.0387\n",
      "Epoch 97/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0964 - val_loss: 0.0369\n",
      "Epoch 98/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0927 - val_loss: 0.0388\n",
      "Epoch 99/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0942 - val_loss: 0.0472\n",
      "Epoch 100/100\n",
      "1283/1283 [==============================] - 2s 2ms/step - loss: 0.0944 - val_loss: 0.0386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c2fd2db50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train_nf, X_train_nf, epochs=100, shuffle=True, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ESHuD6gQ80M6",
   "metadata": {
    "id": "ESHuD6gQ80M6"
   },
   "source": [
    "#### Saving a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9nx4njq8ng5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9nx4njq8ng5",
    "outputId": "5023e55e-a087-4959-ce9a-9ed18e5198c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ae1/assets\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('models/ae1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0tjfgrft84XK",
   "metadata": {
    "id": "0tjfgrft84XK"
   },
   "source": [
    "#### Loading the model back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "AkRlzLa68_hK",
   "metadata": {
    "id": "AkRlzLa68_hK"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "autoencoder = keras.models.load_model('models/ae1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e1565",
   "metadata": {
    "id": "286e1565"
   },
   "source": [
    "#### Evaluate the loss on non-fraud train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b8e29a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5b8e29a",
    "outputId": "cf270be5-e574-4544-d21b-7313b28d47b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604/1604 [==============================] - 2s 1ms/step - loss: 0.0379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.037930332124233246"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(X_train_nf, X_train_nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4916b",
   "metadata": {
    "id": "fac4916b"
   },
   "source": [
    "#### Evaluate the loss on non-fraud test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96a5dba3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96a5dba3",
    "outputId": "6e785116-19eb-442a-ab25-d3c64da23453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 1ms/step - loss: 0.0372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03717506304383278"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(X_test_nf, X_test_nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddf5a8",
   "metadata": {
    "id": "d4ddf5a8"
   },
   "source": [
    "#### Evaluate the loss on fraud test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50eda294",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50eda294",
    "outputId": "107515e8-36da-443a-d293-7c33ea26db62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 1.8185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8184670209884644"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(X_test_f, X_test_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4909f99",
   "metadata": {
    "id": "f4909f99"
   },
   "source": [
    "#### Function to calculate mse for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e204137c",
   "metadata": {
    "id": "e204137c"
   },
   "outputs": [],
   "source": [
    "def mse_for_each_record(act, pred):\n",
    "    error = act - pred\n",
    "    squared_error = np.square(error)\n",
    "    mean_squared_error = np.mean(squared_error, axis=1)\n",
    "    return mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d7138",
   "metadata": {
    "id": "721d7138"
   },
   "source": [
    "#### Making predictions on the non-fraud train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8fbb663",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8fbb663",
    "outputId": "955fb4af-bb3f-4da1-d49d-d4ecfe938b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51317, 29)\n",
      "(51317,)\n"
     ]
    }
   ],
   "source": [
    "pred_train_nf = autoencoder.predict(X_train_nf)\n",
    "print(pred_train_nf.shape)\n",
    "\n",
    "mse_train_nf = mse_for_each_record(X_train_nf, pred_train_nf)\n",
    "print(mse_train_nf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8be93",
   "metadata": {
    "id": "cea8be93"
   },
   "source": [
    "#### Making predictions on the non-fraud test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23ce016a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23ce016a",
    "outputId": "11a12949-eadb-46bd-a0f2-92908f7c91e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12830, 29)\n",
      "(12830,)\n"
     ]
    }
   ],
   "source": [
    "pred_test_nf = autoencoder.predict(X_test_nf)\n",
    "print(pred_test_nf.shape)\n",
    "\n",
    "mse_test_nf = mse_for_each_record(X_test_nf, pred_test_nf)\n",
    "print(mse_test_nf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60826c28",
   "metadata": {
    "id": "60826c28"
   },
   "source": [
    "#### Making predictions on the fraud test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abdd590c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abdd590c",
    "outputId": "307d13d6-177f-4b7b-c294-d04fcb23edd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 29)\n",
      "(308,)\n"
     ]
    }
   ],
   "source": [
    "pred_test_f = autoencoder.predict(X_test_f)\n",
    "print(pred_test_f.shape)\n",
    "\n",
    "mse_test_f = mse_for_each_record(X_test_f, pred_test_f)\n",
    "print(mse_test_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da959ae9",
   "metadata": {
    "id": "da959ae9"
   },
   "source": [
    "#### Explore and identify right cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ac8b075",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "8ac8b075",
    "outputId": "b35b5fdb-e3b6-4c63-ec91-05bf9ce70794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x7f1c2bbc0e10>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f1c2bc0ff90>,\n",
       "  <matplotlib.lines.Line2D at 0x7f1c2bc0f410>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f1c2bcad9d0>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f1c2bcadc50>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x7f1c2bbc0150>,\n",
       "  <matplotlib.lines.Line2D at 0x7f1c2bc0fbd0>]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mse box plots of non-fraud train, non-fraud test and fraud test data\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot(mse_train_nf)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(mse_test_nf)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot(mse_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8356b924",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8356b924",
    "outputId": "21a93d19-4f8a-4e2e-e620-243ad023b130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------mse_train_nf-------\n",
      "count    51317.000000\n",
      "mean         0.037930\n",
      "std          0.250271\n",
      "min          0.001510\n",
      "25%          0.010196\n",
      "50%          0.016795\n",
      "75%          0.027703\n",
      "max         24.815616\n",
      "dtype: float64\n",
      "\n",
      "-------mse_test_NF-------\n",
      "count    12830.000000\n",
      "mean         0.037175\n",
      "std          0.189868\n",
      "min          0.001692\n",
      "25%          0.010263\n",
      "50%          0.016839\n",
      "75%          0.027728\n",
      "max         14.581040\n",
      "dtype: float64\n",
      "\n",
      "-------mse_test_f-------\n",
      "count    308.000000\n",
      "mean       1.818467\n",
      "std        2.797170\n",
      "min        0.008440\n",
      "25%        0.549259\n",
      "50%        1.004228\n",
      "75%        1.990687\n",
      "max       21.750461\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics on mse of non-fraud train, non-fraud test and fraud test data\n",
    "print(\"-------mse_train_nf-------\")\n",
    "print(pd.Series(mse_train_nf).describe())\n",
    "print(\"\\n-------mse_test_NF-------\")\n",
    "print(pd.Series(mse_test_nf).describe())\n",
    "print(\"\\n-------mse_test_f-------\")\n",
    "print(pd.Series(mse_test_f).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a57065",
   "metadata": {
    "id": "14a57065"
   },
   "source": [
    "#### Define cut-off error/MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f64a510e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f64a510e",
    "outputId": "3673b281-d612-47e9-9ddc-368adf765cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off = 0.35\n"
     ]
    }
   ],
   "source": [
    "cut_off = np.round(np.percentile(mse_train_nf,99),2)\n",
    "print(\"Cut-off = {}\".format(cut_off))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29e485",
   "metadata": {
    "id": "df29e485"
   },
   "source": [
    "#### % of correctly predicted non-fraud train, non-fraud test and fraud test records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2337306",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2337306",
    "outputId": "cc38e8b1-ad2c-422f-e1f7-ec0eaf09dc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-fraud train records = 99.0%\n",
      "Non-fraud test records  = 99.0%\n",
      "Fraud test records      = 82.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-fraud train records = {}%\".format(np.round(np.sum(mse_train_nf <= cut_off)/train_nf.shape[0],2)*100))\n",
    "print(\"Non-fraud test records  = {}%\".format(np.round(np.sum(mse_test_nf <= cut_off)/test_nf.shape[0],2)*100))\n",
    "print(\"Fraud test records      = {}%\".format(np.round(np.sum(mse_test_f > cut_off)/test_f.shape[0],2)*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "20210904_Batch95_DSC 7221_AutoEncoders_Fraud_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
