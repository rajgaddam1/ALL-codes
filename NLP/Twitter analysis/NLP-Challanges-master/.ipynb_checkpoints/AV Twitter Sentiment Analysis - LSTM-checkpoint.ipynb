{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter Sentiment Analysis\n",
    "\n",
    "The objective of this task is to detect hate speech in tweets.\n",
    "\n",
    "We are given a training sample of tweets and labels, where label '1' denotes negative tweet (with hate speech) and \n",
    "label '0' denotes positive tweet (with out hate speech).\n",
    "\n",
    "Our objective is to predict the labels on the test dataset.\n",
    "\n",
    "#### Data\n",
    "Our overall collection of tweets was split in the ratio of 65:35 into training and testing data. Out of the testing data, 30% is public and the rest is private.\n",
    "\n",
    "#### Evaluation Metric:\n",
    "The metric used for evaluating the performance of classification model would be F1-Score.\n",
    "\n",
    "Precision = TP/TP+FP\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading train and test data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\pdrva\\Desktop\\Divya\\Kaggle\\Analytics Vidya Hackthon Data\\Twitter Sentiment Analysis\")\n",
    "import pandas as pd\n",
    "train=pd.read_csv(\"train_E6oV3lV.csv\")\n",
    "test=pd.read_csv(\"test_tweets_anuFYb8.csv\")\n",
    "submission=pd.read_csv(\"sample_submission_gfvA5FD.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Understanding data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train data has {} rows and {} columns\".format(train.shape[0],train.shape[1]))\n",
    "print(\"test data has {} rows and {} columns\".format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train datatypes-->\n",
      "\n",
      "id        int64\n",
      "label     int64\n",
      "tweet    object\n",
      "dtype: object\n",
      "\n",
      "test datatypes-->\n",
      "\n",
      "id        int64\n",
      "tweet    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\ntrain datatypes-->\\n\")\n",
    "print(train.dtypes)\n",
    "print(\"\\ntest datatypes-->\\n\")\n",
    "print(test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([29720,  2242], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(train['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is class imbalance in the data.\n",
    "Only 7 percent of the training records have hate speech while the rest of the records doesn't have hate speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1      0   @user when a father is dysfunctional and is s...\n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3      0                                bihday your majesty\n",
       "3    4      0  #model   i love u take with u all the time in ...\n",
       "4    5      0             factsguide: society now    #motivation\n",
       "5    6      0  [2/2] huge fan fare and big talking before the...\n",
       "6    7      0   @user camping tomorrow @user @user @user @use...\n",
       "7    8      0  the next school year is the year for exams.ð...\n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11      0   â #ireland consumer price index (mom) climb...\n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...\n",
       "16  17      0  i am thankful for having a paner. #thankful #p...\n",
       "17  18      1                             retweet if you agree! \n",
       "18  19      0  its #friday! ð smiles all around via ig use...\n",
       "19  20      0  as we all know, essential oils are not made of..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has @User mentions and #tag mentions, preprocessing step involves removing these tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_handles(text,pattern):\n",
    "    handles=re.findall(pattern,text)\n",
    "    for handle in handles:\n",
    "        text=re.sub(handle,'',text)\n",
    "    return text\n",
    "\n",
    "# Remove twitter handles\n",
    "train['clean_tweet']=train.tweet.apply(lambda tweet: remove_handles(str(tweet),\"@[\\w]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camping tomorrow        dannyâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcome here !  i'm   it's so #gr8 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "      <td>#cnn calls #michigan middle school 'build the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet  \\\n",
       "0    1      0   @user when a father is dysfunctional and is s...   \n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2    3      0                                bihday your majesty   \n",
       "3    4      0  #model   i love u take with u all the time in ...   \n",
       "4    5      0             factsguide: society now    #motivation   \n",
       "5    6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6    7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7    8      0  the next school year is the year for exams.ð...   \n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "10  11      0   â #ireland consumer price index (mom) climb...   \n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...   \n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...   \n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...   \n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...   \n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...   \n",
       "16  17      0  i am thankful for having a paner. #thankful #p...   \n",
       "17  18      1                             retweet if you agree!    \n",
       "18  19      0  its #friday! ð smiles all around via ig use...   \n",
       "19  20      0  as we all know, essential oils are not made of...   \n",
       "\n",
       "                                          clean_tweet  \n",
       "0     when a father is dysfunctional and is so sel...  \n",
       "1     thanks for #lyft credit i can't use cause th...  \n",
       "2                                 bihday your majesty  \n",
       "3   #model   i love u take with u all the time in ...  \n",
       "4              factsguide: society now    #motivation  \n",
       "5   [2/2] huge fan fare and big talking before the...  \n",
       "6                    camping tomorrow        dannyâ¦  \n",
       "7   the next school year is the year for exams.ð...  \n",
       "8   we won!!! love the land!!! #allin #cavs #champ...  \n",
       "9               welcome here !  i'm   it's so #gr8 !   \n",
       "10   â #ireland consumer price index (mom) climb...  \n",
       "11  we are so selfish. #orlando #standwithorlando ...  \n",
       "12  i get to see my daddy today!!   #80days #getti...  \n",
       "13   #cnn calls #michigan middle school 'build the...  \n",
       "14  no comment!  in #australia   #opkillingbay #se...  \n",
       "15  ouch...junior is angryð#got7 #junior #yugyo...  \n",
       "16  i am thankful for having a paner. #thankful #p...  \n",
       "17                             retweet if you agree!   \n",
       "18  its #friday! ð smiles all around via ig use...  \n",
       "19  as we all know, essential oils are not made of...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specialchars(text,pattern):\n",
    "    text=re.sub(pattern,' ',text)\n",
    "    return text\n",
    "\n",
    "# Remove special characters,numbers and punctuations except \" # \" and \" ' \"\n",
    "train['clean_tweet']=train.clean_tweet.apply(lambda tweet: remove_specialchars(str(tweet),\"[^a-zA-Z'#]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camping tomorrow        danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won    love the land    #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcome here    i'm   it's so #gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "      <td>#ireland consumer price index  mom  climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "      <td>we are so selfish  #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "      <td>i get to see my daddy today     #  days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "      <td>#cnn calls #michigan middle school 'build the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "      <td>no comment   in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "      <td>ouch   junior is angry    #got  #junior #yugyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "      <td>i am thankful for having a paner  #thankful #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>retweet if you agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "      <td>its #friday       smiles all around via ig use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "      <td>as we all know  essential oils are not made of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet  \\\n",
       "0    1      0   @user when a father is dysfunctional and is s...   \n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2    3      0                                bihday your majesty   \n",
       "3    4      0  #model   i love u take with u all the time in ...   \n",
       "4    5      0             factsguide: society now    #motivation   \n",
       "5    6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6    7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7    8      0  the next school year is the year for exams.ð...   \n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "10  11      0   â #ireland consumer price index (mom) climb...   \n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...   \n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...   \n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...   \n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...   \n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...   \n",
       "16  17      0  i am thankful for having a paner. #thankful #p...   \n",
       "17  18      1                             retweet if you agree!    \n",
       "18  19      0  its #friday! ð smiles all around via ig use...   \n",
       "19  20      0  as we all know, essential oils are not made of...   \n",
       "\n",
       "                                          clean_tweet  \n",
       "0     when a father is dysfunctional and is so sel...  \n",
       "1     thanks for #lyft credit i can't use cause th...  \n",
       "2                                 bihday your majesty  \n",
       "3   #model   i love u take with u all the time in ...  \n",
       "4              factsguide  society now    #motivation  \n",
       "5         huge fan fare and big talking before the...  \n",
       "6                    camping tomorrow        danny     \n",
       "7   the next school year is the year for exams    ...  \n",
       "8   we won    love the land    #allin #cavs #champ...  \n",
       "9               welcome here    i'm   it's so #gr      \n",
       "10       #ireland consumer price index  mom  climb...  \n",
       "11  we are so selfish  #orlando #standwithorlando ...  \n",
       "12  i get to see my daddy today     #  days #getti...  \n",
       "13   #cnn calls #michigan middle school 'build the...  \n",
       "14  no comment   in #australia   #opkillingbay #se...  \n",
       "15  ouch   junior is angry    #got  #junior #yugyo...  \n",
       "16  i am thankful for having a paner  #thankful #p...  \n",
       "17                             retweet if you agree    \n",
       "18  its #friday       smiles all around via ig use...  \n",
       "19  as we all know  essential oils are not made of...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace short cuts with actual words\n",
    "shortcuts = {'u': 'you', 'y': 'why', 'r': 'are', 'doin': 'doing', 'hw': 'how', 'k': 'okay', 'm': 'am', 'b4': 'before',\n",
    "            'idc': \"i do not care\", 'ty': 'thankyou', 'wlcm': 'welcome', 'bc': 'because', '<3': 'love', 'xoxo': 'love',\n",
    "            'ttyl': 'talk to you later', 'gr8': 'great', 'bday': 'birthday', 'awsm': 'awesome', 'gud': 'good', 'h8': 'hate',\n",
    "            'lv': 'love', 'dm': 'direct message', 'rt': 'retweet', 'wtf': 'hate', 'idgaf': 'hate',\n",
    "             'irl': 'in real life', 'yolo': 'you only live once', 'ur': 'your'}\n",
    "\n",
    "def replace_shortcuts(text):\n",
    "    for i,token in enumerate(text):\n",
    "        if token in shortcuts.keys():\n",
    "            token=shortcuts[token]\n",
    "            text[i]=token\n",
    "    return text\n",
    "\n",
    "train.clean_tweet=train.clean_tweet.apply(lambda tweet: replace_shortcuts(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>[thanks, for, #lyft, credit, i, can't, use, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>[#model, i, love, you, take, with, you, all, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>[factsguide, society, now, #motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[huge, fan, fare, and, big, talking, before, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>[camping, tomorrow, danny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>[the, next, school, year, is, the, year, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>[we, won, love, the, land, #allin, #cavs, #cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>[welcome, here, i'm, it's, so, #gr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "      <td>[#ireland, consumer, price, index, mom, climbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "      <td>[we, are, so, selfish, #orlando, #standwithorl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "      <td>[i, get, to, see, my, daddy, today, #, days, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "      <td>[#cnn, calls, #michigan, middle, school, 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "      <td>[no, comment, in, #australia, #opkillingbay, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "      <td>[ouch, junior, is, angry, #got, #junior, #yugy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "      <td>[i, am, thankful, for, having, a, paner, #than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>[retweet, if, you, agree]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "      <td>[its, #friday, smiles, all, around, via, ig, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "      <td>[as, we, all, know, essential, oils, are, not,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet  \\\n",
       "0    1      0   @user when a father is dysfunctional and is s...   \n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2    3      0                                bihday your majesty   \n",
       "3    4      0  #model   i love u take with u all the time in ...   \n",
       "4    5      0             factsguide: society now    #motivation   \n",
       "5    6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6    7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7    8      0  the next school year is the year for exams.ð...   \n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "10  11      0   â #ireland consumer price index (mom) climb...   \n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...   \n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...   \n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...   \n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...   \n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...   \n",
       "16  17      0  i am thankful for having a paner. #thankful #p...   \n",
       "17  18      1                             retweet if you agree!    \n",
       "18  19      0  its #friday! ð smiles all around via ig use...   \n",
       "19  20      0  as we all know, essential oils are not made of...   \n",
       "\n",
       "                                          clean_tweet  \n",
       "0   [when, a, father, is, dysfunctional, and, is, ...  \n",
       "1   [thanks, for, #lyft, credit, i, can't, use, ca...  \n",
       "2                             [bihday, your, majesty]  \n",
       "3   [#model, i, love, you, take, with, you, all, t...  \n",
       "4             [factsguide, society, now, #motivation]  \n",
       "5   [huge, fan, fare, and, big, talking, before, t...  \n",
       "6                          [camping, tomorrow, danny]  \n",
       "7   [the, next, school, year, is, the, year, for, ...  \n",
       "8   [we, won, love, the, land, #allin, #cavs, #cha...  \n",
       "9                 [welcome, here, i'm, it's, so, #gr]  \n",
       "10  [#ireland, consumer, price, index, mom, climbe...  \n",
       "11  [we, are, so, selfish, #orlando, #standwithorl...  \n",
       "12  [i, get, to, see, my, daddy, today, #, days, #...  \n",
       "13  [#cnn, calls, #michigan, middle, school, 'buil...  \n",
       "14  [no, comment, in, #australia, #opkillingbay, #...  \n",
       "15  [ouch, junior, is, angry, #got, #junior, #yugy...  \n",
       "16  [i, am, thankful, for, having, a, paner, #than...  \n",
       "17                          [retweet, if, you, agree]  \n",
       "18  [its, #friday, smiles, all, around, via, ig, u...  \n",
       "19  [as, we, all, know, essential, oils, are, not,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_extract(text):\n",
    "    tweet=(\" \").join(text)\n",
    "    hashtags=re.findall(r\"#(\\w+)\",tweet)\n",
    "    return hashtags\n",
    "\n",
    "# Extract hashtags to a new column\n",
    "train['hashtags']=train.clean_tweet.apply(lambda tweet: hashtag_extract(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hash(text,pattern):\n",
    "    for i,token in enumerate(text):\n",
    "        word=re.sub(pattern,'',token)\n",
    "        text[i]=word\n",
    "    return text\n",
    "\n",
    "# Remove # from tweet\n",
    "train['clean_tweet']=train.clean_tweet.apply(lambda tweet: remove_hash(tweet,'#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>[thanks, for, lyft, credit, i, can't, use, cau...</td>\n",
       "      <td>[lyft, disapointed, getthanked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, i, love, you, take, with, you, all, th...</td>\n",
       "      <td>[model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[huge, fan, fare, and, big, talking, before, t...</td>\n",
       "      <td>[allshowandnogo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>[camping, tomorrow, danny]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>[the, next, school, year, is, the, year, for, ...</td>\n",
       "      <td>[school, exams, hate, imagine, actorslife, rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>[we, won, love, the, land, allin, cavs, champi...</td>\n",
       "      <td>[allin, cavs, champions, cleveland, clevelandc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>[welcome, here, i'm, it's, so, gr]</td>\n",
       "      <td>[gr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "      <td>[ireland, consumer, price, index, mom, climbed...</td>\n",
       "      <td>[ireland, blog, silver, gold, forex]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "      <td>[we, are, so, selfish, orlando, standwithorlan...</td>\n",
       "      <td>[orlando, standwithorlando, pulseshooting, orl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "      <td>[i, get, to, see, my, daddy, today, , days, ge...</td>\n",
       "      <td>[gettingfed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "      <td>[cnn, calls, michigan, middle, school, 'build,...</td>\n",
       "      <td>[cnn, michigan, tcot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "      <td>[no, comment, in, australia, opkillingbay, sea...</td>\n",
       "      <td>[australia, opkillingbay, seashepherd, helpcov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>ouch...junior is angryð#got7 #junior #yugyo...</td>\n",
       "      <td>[ouch, junior, is, angry, got, junior, yugyoem...</td>\n",
       "      <td>[got, junior, yugyoem, omg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>i am thankful for having a paner. #thankful #p...</td>\n",
       "      <td>[i, am, thankful, for, having, a, paner, thank...</td>\n",
       "      <td>[thankful, positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "      <td>[retweet, if, you, agree]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>its #friday! ð smiles all around via ig use...</td>\n",
       "      <td>[its, friday, smiles, all, around, via, ig, us...</td>\n",
       "      <td>[friday, cookies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>as we all know, essential oils are not made of...</td>\n",
       "      <td>[as, we, all, know, essential, oils, are, not,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet  \\\n",
       "0    1      0   @user when a father is dysfunctional and is s...   \n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2    3      0                                bihday your majesty   \n",
       "3    4      0  #model   i love u take with u all the time in ...   \n",
       "4    5      0             factsguide: society now    #motivation   \n",
       "5    6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6    7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7    8      0  the next school year is the year for exams.ð...   \n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "10  11      0   â #ireland consumer price index (mom) climb...   \n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...   \n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...   \n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...   \n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se...   \n",
       "15  16      0  ouch...junior is angryð#got7 #junior #yugyo...   \n",
       "16  17      0  i am thankful for having a paner. #thankful #p...   \n",
       "17  18      1                             retweet if you agree!    \n",
       "18  19      0  its #friday! ð smiles all around via ig use...   \n",
       "19  20      0  as we all know, essential oils are not made of...   \n",
       "\n",
       "                                          clean_tweet  \\\n",
       "0   [when, a, father, is, dysfunctional, and, is, ...   \n",
       "1   [thanks, for, lyft, credit, i, can't, use, cau...   \n",
       "2                             [bihday, your, majesty]   \n",
       "3   [model, i, love, you, take, with, you, all, th...   \n",
       "4              [factsguide, society, now, motivation]   \n",
       "5   [huge, fan, fare, and, big, talking, before, t...   \n",
       "6                          [camping, tomorrow, danny]   \n",
       "7   [the, next, school, year, is, the, year, for, ...   \n",
       "8   [we, won, love, the, land, allin, cavs, champi...   \n",
       "9                  [welcome, here, i'm, it's, so, gr]   \n",
       "10  [ireland, consumer, price, index, mom, climbed...   \n",
       "11  [we, are, so, selfish, orlando, standwithorlan...   \n",
       "12  [i, get, to, see, my, daddy, today, , days, ge...   \n",
       "13  [cnn, calls, michigan, middle, school, 'build,...   \n",
       "14  [no, comment, in, australia, opkillingbay, sea...   \n",
       "15  [ouch, junior, is, angry, got, junior, yugyoem...   \n",
       "16  [i, am, thankful, for, having, a, paner, thank...   \n",
       "17                          [retweet, if, you, agree]   \n",
       "18  [its, friday, smiles, all, around, via, ig, us...   \n",
       "19  [as, we, all, know, essential, oils, are, not,...   \n",
       "\n",
       "                                             hashtags  \n",
       "0                                               [run]  \n",
       "1                     [lyft, disapointed, getthanked]  \n",
       "2                                                  []  \n",
       "3                                             [model]  \n",
       "4                                        [motivation]  \n",
       "5                                    [allshowandnogo]  \n",
       "6                                                  []  \n",
       "7   [school, exams, hate, imagine, actorslife, rev...  \n",
       "8   [allin, cavs, champions, cleveland, clevelandc...  \n",
       "9                                                [gr]  \n",
       "10               [ireland, blog, silver, gold, forex]  \n",
       "11  [orlando, standwithorlando, pulseshooting, orl...  \n",
       "12                                       [gettingfed]  \n",
       "13                              [cnn, michigan, tcot]  \n",
       "14  [australia, opkillingbay, seashepherd, helpcov...  \n",
       "15                        [got, junior, yugyoem, omg]  \n",
       "16                               [thankful, positive]  \n",
       "17                                                 []  \n",
       "18                                  [friday, cookies]  \n",
       "19                                                 []  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting unstructured text to structured numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet with max length has a length of: 42\n"
     ]
    }
   ],
   "source": [
    "def tweet_max_length(tweets):\n",
    "    max_length=0\n",
    "    for tweet in tweets:\n",
    "        if max_length < len(tweet):\n",
    "            max_length = len(tweet)\n",
    "    return max_length\n",
    "\n",
    "max_length=tweet_max_length(train.clean_tweet)\n",
    "print(\"tweet with max length has a length of:\", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_tokens(text):\n",
    "    return (' '.join(text))\n",
    "\n",
    "train.clean_tweet=train.clean_tweet.apply(lambda tweet: join_tokens(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>[run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit i can't use cause they ...</td>\n",
       "      <td>[lyft, disapointed, getthanked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>[model]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for lyft credit i can't use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                          hashtags  \n",
       "0                            [run]  \n",
       "1  [lyft, disapointed, getthanked]  \n",
       "2                               []  \n",
       "3                          [model]  \n",
       "4                     [motivation]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Downloading pre-trained 100-dimensional glove embeddings\n",
    "\n",
    "os.chdir(r\"C:\\Users\\pdrva\\Desktop\\Divya\\INSOFE\\Day29\\20200202_Batch_73_CSE_7321c_Lab05_RNN_Data\\glove_100d\")\n",
    "embeddings_index = {}\n",
    "f = open( 'glove.6B.100d.txt',encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 40000 # Vocabulary size\n",
    "MAX_SEQUENCE_LENGTH = 42 # Number of time steps (at each time step one word/word vector is given as input)\n",
    "embedding_size = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38582 unique tokens.\n",
      "Shape of data tensor: (31962, 42)\n",
      "Shape of label tensor: (31962,)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text samples into a 2D tensor\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(train.clean_tweet)\n",
    "sequences = tokenizer.texts_to_sequences(train.clean_tweet)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels=np.asarray(train.label)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25570, 42)\n",
      "(25570,)\n",
      "(6392, 42)\n",
      "(6392,)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "VALIDATION_SPLIT=0.2\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_NUM_WORDS, (len(word_index)+1))\n",
    "embedding_matrix = np.zeros((num_words, embedding_size))\n",
    "for word, i in word_index.items():\n",
    "    if i < num_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38583, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LSTM for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "Train on 25570 samples, validate on 6392 samples\n",
      "Epoch 1/50\n",
      "25570/25570 [==============================] - 37s 1ms/step - loss: 4.6052 - acc: 0.9284 - val_loss: 0.5318 - val_acc: 0.9344\n",
      "Epoch 2/50\n",
      "25570/25570 [==============================] - 32s 1ms/step - loss: 0.2528 - acc: 0.9423 - val_loss: 0.2012 - val_acc: 0.9441\n",
      "Epoch 3/50\n",
      "25570/25570 [==============================] - 35s 1ms/step - loss: 0.1551 - acc: 0.9541 - val_loss: 0.1746 - val_acc: 0.9520\n",
      "Epoch 4/50\n",
      "25570/25570 [==============================] - 35s 1ms/step - loss: 0.1277 - acc: 0.9636 - val_loss: 0.1604 - val_acc: 0.9510\n",
      "Epoch 5/50\n",
      "25570/25570 [==============================] - 35s 1ms/step - loss: 0.1122 - acc: 0.9685 - val_loss: 0.1650 - val_acc: 0.9495\n",
      "Epoch 6/50\n",
      "25570/25570 [==============================] - 33s 1ms/step - loss: 0.0932 - acc: 0.9737 - val_loss: 0.1661 - val_acc: 0.9549\n",
      "Epoch 7/50\n",
      "25570/25570 [==============================] - 33s 1ms/step - loss: 0.0794 - acc: 0.9786 - val_loss: 0.1581 - val_acc: 0.9609\n",
      "Epoch 8/50\n",
      "25570/25570 [==============================] - 34s 1ms/step - loss: 0.0644 - acc: 0.9828 - val_loss: 0.1670 - val_acc: 0.9609\n",
      "Epoch 9/50\n",
      "25570/25570 [==============================] - 33s 1ms/step - loss: 0.0521 - acc: 0.9873 - val_loss: 0.1769 - val_acc: 0.9626\n",
      "Epoch 10/50\n",
      "25570/25570 [==============================] - 34s 1ms/step - loss: 0.0461 - acc: 0.9884 - val_loss: 0.1816 - val_acc: 0.9599\n",
      "Epoch 11/50\n",
      "25570/25570 [==============================] - 33s 1ms/step - loss: 0.0430 - acc: 0.9894 - val_loss: 0.1786 - val_acc: 0.9584\n",
      "Epoch 12/50\n",
      "25570/25570 [==============================] - 33s 1ms/step - loss: 0.0376 - acc: 0.9914 - val_loss: 0.1778 - val_acc: 0.9599\n",
      "Epoch 13/50\n",
      "25570/25570 [==============================] - 38s 1ms/step - loss: 0.0370 - acc: 0.9911 - val_loss: 0.1755 - val_acc: 0.9612\n",
      "Epoch 14/50\n",
      "25570/25570 [==============================] - 34s 1ms/step - loss: 0.0314 - acc: 0.9928 - val_loss: 0.1968 - val_acc: 0.9607\n",
      "Epoch 15/50\n",
      "25570/25570 [==============================] - 33s 1ms/step - loss: 0.0327 - acc: 0.9932 - val_loss: 0.1776 - val_acc: 0.9598\n",
      "Epoch 16/50\n",
      "25570/25570 [==============================] - 36s 1ms/step - loss: 0.0283 - acc: 0.9937 - val_loss: 0.1698 - val_acc: 0.9581\n",
      "Epoch 17/50\n",
      "25570/25570 [==============================] - 34s 1ms/step - loss: 0.0272 - acc: 0.9944 - val_loss: 0.1678 - val_acc: 0.9595\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "print('Training model.')\n",
    "nb_epochs =50\n",
    "\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "\n",
    "mc = ModelCheckpoint(\"weights.{epoch:02d}-{val_acc:.2f}.hdf5\", monitor='val_loss',mode='min', save_best_only=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "z = Dropout(0.2)(embedded_sequences)\n",
    "z = Bidirectional(LSTM(16,kernel_regularizer=regularizers.l2(0.1)))(z)\n",
    "z = Dropout(0.3)(z)\n",
    "preds_lstm = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001)\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
    "\n",
    "model_lstm = Model(sequence_input, preds_lstm)\n",
    "model_lstm.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['acc'])\n",
    "\n",
    "model_lstm_hist = model_lstm.fit(x_train, y_train,\n",
    "                  batch_size=128,\n",
    "                  epochs=nb_epochs,callbacks=[mc,es],\n",
    "                  validation_data=(x_val, y_val)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "\n",
    "path=os.path.join(os.getcwd(),\"*\")\n",
    "list_of_files = glob.glob(path) # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "model = load_model(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train=model_lstm.predict(x_train)\n",
    "preds_val=model_lstm.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = (preds_train >= 0.28).astype(np.int)\n",
    "preds_val = (preds_val >= 0.28).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23693    63]\n",
      " [   12  1802]]\n",
      "[[5821  143]\n",
      " [ 156  272]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_train,preds_train))\n",
    "print(confusion_matrix(y_val,preds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.997066875244427\n",
      "F1 Score:  0.9796140255504213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "print('Accuracy:', accuracy_score(preds_train, y_train))\n",
    "print(\"F1 Score: \", f1_score(preds_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9532227784730913\n",
      "F1 Score:  0.6453143534994069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "print('Accuracy:', accuracy_score(preds_val, y_val))\n",
    "print(\"F1 Score: \", f1_score(preds_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\pdrva\\Desktop\\Divya\\Kaggle\\Analytics Vidya Hackthon Data\\Twitter Sentiment Analysis\")\n",
    "test=pd.read_csv(\"test_tweets_anuFYb8.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove twitter handles\n",
    "test['clean_tweet']=test.tweet.apply(lambda tweet: remove_handles(str(tweet),\"@[\\w]*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  #studiolife #aislife #requires #passion #dedic...  \n",
       "1    #white #supremacists want everyone to see th...  \n",
       "2  safe ways to heal your #acne!!    #altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4    3rd #bihday to my amazing, hilarious #nephew...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters,numbers and punctuations except \" # \" and \" ' \"\n",
    "test['clean_tweet']=test.clean_tweet.apply(lambda tweet: remove_specialchars(str(tweet),\"[^a-zA-Z'#]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>#white #supremacists want everyone to see th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your #acne      #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd #bihday to my amazing  hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  #studiolife #aislife #requires #passion #dedic...  \n",
       "1    #white #supremacists want everyone to see th...  \n",
       "2  safe ways to heal your #acne      #altwaystohe...  \n",
       "3  is the hp and the cursed child book up for res...  \n",
       "4     rd #bihday to my amazing  hilarious #nephew...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace short cuts with actual words\n",
    "test.clean_tweet=test.clean_tweet.apply(lambda tweet: replace_shortcuts(tweet.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>[#studiolife, #aislife, #requires, #passion, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>[#white, #supremacists, want, everyone, to, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>[safe, ways, to, heal, your, #acne, #altwaysto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>[rd, #bihday, to, my, amazing, hilarious, #nep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  [#studiolife, #aislife, #requires, #passion, #...  \n",
       "1  [#white, #supremacists, want, everyone, to, se...  \n",
       "2  [safe, ways, to, heal, your, #acne, #altwaysto...  \n",
       "3  [is, the, hp, and, the, cursed, child, book, u...  \n",
       "4  [rd, #bihday, to, my, amazing, hilarious, #nep...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hashtags to a new column\n",
    "test['hashtags']=test.clean_tweet.apply(lambda tweet: hashtag_extract(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove # from tweet\n",
    "test['clean_tweet']=test.clean_tweet.apply(lambda tweet: remove_hash(tweet,'#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>[white, supremacists, want, everyone, to, see,...</td>\n",
       "      <td>[white, supremacists, birds, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>[safe, ways, to, heal, your, acne, altwaystohe...</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[is, the, hp, and, the, cursed, child, book, u...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>[rd, bihday, to, my, amazing, hilarious, nephe...</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  [studiolife, aislife, requires, passion, dedic...   \n",
       "1  [white, supremacists, want, everyone, to, see,...   \n",
       "2  [safe, ways, to, heal, your, acne, altwaystohe...   \n",
       "3  [is, the, hp, and, the, cursed, child, book, u...   \n",
       "4  [rd, bihday, to, my, amazing, hilarious, nephe...   \n",
       "\n",
       "                                            hashtags  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1                [white, supremacists, birds, movie]  \n",
       "2            [acne, altwaystoheal, healthy, healing]  \n",
       "3                [harrypotter, pottermore, favorite]  \n",
       "4                                   [bihday, nephew]  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet in test data with max length has a length of: 31\n"
     ]
    }
   ],
   "source": [
    "test_max_length=tweet_max_length(test.clean_tweet)\n",
    "print(\"tweet in test data with max length has a length of:\", test_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.clean_tweet=test.clean_tweet.apply(lambda tweet: join_tokens(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white supremacists want everyone to see the ne...</td>\n",
       "      <td>[white, supremacists, birds, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways to heal your acne altwaystoheal heal...</td>\n",
       "      <td>[acne, altwaystoheal, healthy, healing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[harrypotter, pottermore, favorite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd bihday to my amazing hilarious nephew eli a...</td>\n",
       "      <td>[bihday, nephew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet  \\\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1  31964   @user #white #supremacists want everyone to s...   \n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3  31966  is the hp and the cursed child book up for res...   \n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  white supremacists want everyone to see the ne...   \n",
       "2  safe ways to heal your acne altwaystoheal heal...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4  rd bihday to my amazing hilarious nephew eli a...   \n",
       "\n",
       "                                            hashtags  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1                [white, supremacists, birds, movie]  \n",
       "2            [acne, altwaystoheal, healthy, healing]  \n",
       "3                [harrypotter, pottermore, favorite]  \n",
       "4                                   [bihday, nephew]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (17197, 42)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text samples into a 2D tensor\n",
    "test_sequences = tokenizer.texts_to_sequences(test.clean_tweet)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions on test data with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>31963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>31964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>31967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  31963      0\n",
       "1  31964      0\n",
       "2  31965      0\n",
       "3  31966      0\n",
       "4  31967      0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test=model_lstm.predict(test_data)\n",
    "submission['label'] = (preds_test >= 0.28).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15923\n",
       "1     1274\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\pdrva\\Desktop\\Divya\\Kaggle\\Analytics Vidya Hackthon Data\\Twitter Sentiment Analysis')\n",
    "submission.to_csv('Submission_lstm.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
